{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysal as ps\n",
    "import seaborn as sns\n",
    "from scipy.stats import stats\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import wkt\n",
    "\n",
    "#Import tract data\n",
    "df = pd.read_csv('data/tracts_agg.csv', dtype={'tract':str}, index_col='tract', )\n",
    "df['tract_geometry'] = df['tract_geometry'].apply(wkt.loads)\n",
    "df.rename(columns={'tract_geometry':'geometry'}, inplace=True)\n",
    "gdf = gpd.GeoDataFrame(df, geometry='geometry', crs='WGS84')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep\n",
    "gdf['exploitation_rate'].replace({np.inf:np.nan}, inplace=True)\n",
    "gdf['exploitation_rate_local'].replace({np.inf:np.nan}, inplace=True)\n",
    "gdf['exploitation_rate_external'].replace({np.inf:np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate maximum nearest neighbor distance so each unit is assured of >=1 neighbor\n",
    "x = gdf.centroid.x\n",
    "y = gdf.centroid.y\n",
    "coords = np.array([x, y]).T\n",
    "threshold = ps.lib.weights.min_threshold_distance(coords)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = -1 for linear, alpha = -2 for gravity model\n",
    "w_dist = ps.lib.weights.distance.DistanceBand.from_dataframe(gdf,\n",
    "                                                             threshold=threshold,\n",
    "                                                             binary=False,\n",
    "                                                             alpha=-1)\n",
    "w_dist.set_transform('R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate missing variables across all analysis columns\n",
    "\n",
    "cols = ['exploitation_rate', 'rent_burden', 'total_poverty', 'gross_rent_paid_perpar', 'med_income', 'pct_latino', 'exploitation_rate_external', 'exploitation_rate_local', 'pct_foreignborn']\n",
    "def interpolate_missing(cols,gdf=gdf,w_dist=w_dist):\n",
    "    for col in cols:\n",
    "        nulls = gdf[pd.isnull(gdf[col])].index\n",
    "\n",
    "        estimates = {}\n",
    "        for tract in nulls:\n",
    "            neighbors = w_dist[tract]\n",
    "            inv_dist_wt = pd.Series(w_dist[tract])\n",
    "            estimates[tract] = (gdf.loc[neighbors, col] * inv_dist_wt).sum()\n",
    "            gdf.loc[tract,col] = estimates[tract]\n",
    "interpolate_missing(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform exploitation rate\n",
    "gdf['exploitation_rate_log'] = np.log(gdf['exploitation_rate'])\n",
    "\n",
    "# Transform income to thousands\n",
    "gdf['med_income_thousands'] = gdf['med_income'] / 1000\n",
    "gdf['gross_rent_paid_perpar_thousands'] = gdf['gross_rent_paid_perpar'] / 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "\n",
    "def simple_map(gdf, column, cmap, title, scheme=None):\n",
    "    ax = gdf.plot(column=column, cmap=cmap, scheme=scheme, legend=True)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig('figures/{}.png'.format(column), bbox_inches='tight', dpi=400, facecolor='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_map(gdf,'exploitation_rate', cmap='viridis', title='Rental Exploitation Rate in San Diego County, CA', scheme='fisherjenks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_map(gdf,'exploitation_rate_log', cmap='viridis', title='Rental Exploitation Rate (Log-Transformed) in San Diego County, CA', scheme='fisherjenks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_map(gdf,'renter_poverty', cmap='viridis', title='Poverty Rate for Renters, San Diego County, CA',scheme='fisherjenks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(x=gdf['exploitation_rate'])\n",
    "ax.set_xlabel('Exploitation Rate')\n",
    "ax.set_title('Distribution of Tract-Level Exploitation Rates')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('figures/exploitation_kde.png', bbox_inches='tight', dpi=400, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(x=gdf['exploitation_rate_log'])\n",
    "ax.set_xlabel('Exploitation Rate')\n",
    "ax.set_title('Distribution of Tract-Level Exploitation Rates (Log-transformed)')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('figures/exploitation_kde_log.png', bbox_inches='tight', dpi=400, facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spatial lag\n",
    "col = 'exploitation_rate_log'\n",
    "y = gdf[col]\n",
    "\n",
    "y_lag = ps.lib.weights.lag_spatial(w_dist, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_lag = f'{col}_lag'\n",
    "data_lag = pd.DataFrame(data={col:y, col_lag:y_lag})\n",
    "data_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = ps.explore.esda.Moran(data_lag[col], w_dist)\n",
    "mi.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.z_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.regplot(x=col, y=col_lag, data=data_lag, scatter_kws={'s':1, 'color':'gray'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# standardize the variable's values (i.e., calculate z-scores)\n",
    "y_std = (y - y.mean()) / y.std()\n",
    "\n",
    "# compute spatial lag of standardized values and save as series with same index\n",
    "y_std_lag = pd.Series(ps.lib.weights.lag_spatial(w_dist, y_std),\n",
    "                      index=y_std.index,\n",
    "                      name=col_lag)\n",
    "\n",
    "# estimate a simple linear regression model\n",
    "m, b, r, p, se = stats.linregress(x=y_std, y=y_std_lag)\n",
    "print('m={:.4f}, b={:.4f}, r^2={:.4f}, p={:.4f}'.format(m, b, r ** 2, p))\n",
    "\n",
    "# standardized moran's plot\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.scatter(x=y_std, y=y_std_lag, s=1, color='gray')\n",
    "\n",
    "# draw quadrants and ignore outliers beyond 3 std devs (99.7% of distribution)\n",
    "plt.axvline(0, c='k', alpha=0.5)\n",
    "plt.axhline(0, c='k', alpha=0.5)\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "\n",
    "# draw a line with moran's I as the slope\n",
    "Xs = pd.Series([-3, 3])\n",
    "Ys = Xs * mi.I\n",
    "line = ax.plot(Xs, Ys, lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized moran's plot again, from above, but labeled this time\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(x=y_std, y=y_std_lag, s=1, color='gray')\n",
    "\n",
    "# draw quadrants and ignore outliers beyond 3 std devs\n",
    "plt.axvline(0, c='k', alpha=0.5)\n",
    "plt.axhline(0, c='k', alpha=0.5)\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "\n",
    "# label the quadrants\n",
    "ax.text(0.4, 0.5, 'HH', fontsize=30)\n",
    "ax.text(0.4, -0.6, 'HL', fontsize=30)\n",
    "ax.text(-0.6, 0.5, 'LH', fontsize=30)\n",
    "ax.text(-0.6, -0.6, 'LL', fontsize=30)\n",
    "\n",
    "# draw a line with moran's I as the slope\n",
    "Xs = pd.Series([-3, 3])\n",
    "Ys = Xs * mi.I\n",
    "line = ax.plot(Xs, Ys, lw=2)\n",
    "\n",
    "ax.set_title('Standardized Moran\\'s Plot of Exploitation Rates (log-transformed)')\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('figures/moran_std.png', dpi=400, bbox_inches='tight', facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lisa = ps.explore.esda.Moran_Local(data_lag[col], w_dist)\n",
    "\n",
    "# set the statistical significance threshold (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# identify whether each observation is significant or not\n",
    "# p-value interpretation same as earlier with moran's I\n",
    "data_lag['significant'] = lisa.p_sim < alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the quadrant each observation belongs to\n",
    "data_lag['quadrant'] = lisa.q\n",
    "data_lag['quadrant'] = data_lag['quadrant'].replace({1:'HH', 2:'LH', 3:'LL', 4:'HL'})\n",
    "data_lag['quadrant'].sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "\n",
    "# merge original tracts and LISA quadrants data together, plot tracts basemap\n",
    "tracts_lisa = gdf.merge(data_lag, how='left', left_index=True, right_index=True)\n",
    "tracts_lisa.plot(ax=ax, facecolor='#999999', edgecolor='k', linewidth=0.1)\n",
    "\n",
    "# plot each quandrant's tracts (if significant LISA) in a different color\n",
    "quadrant_colors = {'HH':'r', 'LL':'b', 'LH':'skyblue', 'HL':'pink'}\n",
    "for q, c in quadrant_colors.items():\n",
    "    mask = tracts_lisa['significant'] & (tracts_lisa['quadrant']==q)\n",
    "    rows = tracts_lisa.loc[mask]\n",
    "    rows.plot(ax=ax, color=c, edgecolor='k', linewidth=0.1)\n",
    "\n",
    "# create legend\n",
    "patches = []\n",
    "for label, color in quadrant_colors.items():\n",
    "    patches.append(mpatches.Patch(color=color,label=label))\n",
    "patches.append(mpatches.Patch(color='#999999', label='Not significant'))\n",
    "plt.legend(handles=patches, loc='lower left')\n",
    "\n",
    "ax.set_title('LISA Analysis of Exploitation Rate (log-transformed)')\n",
    "ax.axis('off')\n",
    "fig.savefig('figures/clusters_{}.png'.format(col), dpi=600, bbox_inches='tight', facecolor='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to use in all following analyses\n",
    "predictors = [ 'gross_rent_paid_perpar_thousands', 'renter_poverty', 'pct_foreignborn', 'med_income_thousands', 'pct_latino', 'rent_burden']\n",
    "predictors_nicenames = ['Gross Rent Per Parcel ($1000 USD)', 'Renter Poverty Rate', 'Percent Foreign-Born', 'Median Income ($1000 USD)', 'Percent Hispanic/Latino', 'Percent Rent Burdened']\n",
    "response = 'exploitation_rate_log'\n",
    "\n",
    "stats_ = gdf[[response] + predictors].describe().T.round(2)\n",
    "stats_.to_csv('data/variable_descriptivestats.csv')\n",
    "stats_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create design matrix of predictors (drop nulls) and response matrix\n",
    "X = gdf[predictors].dropna()\n",
    "Y = gdf.loc[X.index][[response]] #slice only those indexed in X (because nulls were dropped)\n",
    "\n",
    "# estimate linear regression model with OLS\n",
    "ols = ps.model.spreg.OLS(y=Y.values,\n",
    "                         x=X.values,\n",
    "                         name_x=X.columns.tolist(),\n",
    "                         name_y=response,\n",
    "                         name_ds='tracts')\n",
    "print(ols.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate the coefficients - output is interpretable as the percent increase (or decrease) in the response for every one-unit increase in the independent variable.\n",
    "# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n",
    "for res,name in zip(((np.exp(ols.betas) - 1) * 100), ols.name_x):\n",
    "    print('{}: {}'.format(name,res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographically-Weighted Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_kernel = False\n",
    "spatial_kernel = 'gaussian'\n",
    "search = 'golden_section'\n",
    "criterion = 'AICc'\n",
    "\n",
    "# select an adaptive (NN) bandwidth for our GWR model, given the data\n",
    "centroids = gdf.loc[X.index].centroid\n",
    "coords = list(zip(centroids.x, centroids.y))\n",
    "sel = ps.model.mgwr.sel_bw.Sel_BW(coords=coords,\n",
    "                                  y=Y.values,\n",
    "                                  X_loc=X.values,\n",
    "                                  kernel=spatial_kernel,\n",
    "                                  fixed=fixed_kernel,\n",
    "                                  spherical=True)\n",
    "nn = sel.search(search_method=search, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the GWR model parameters\n",
    "# pass fixed=False to treat bw as number of NNs (adaptive kernel)\n",
    "model = ps.model.mgwr.gwr.GWR(coords=coords,\n",
    "                              y=Y.values,\n",
    "                              X=X.values,\n",
    "                              bw=nn,\n",
    "                              kernel=spatial_kernel,\n",
    "                              fixed=fixed_kernel)\n",
    "gwr = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a constant was added, so we'll add it to our predictors\n",
    "cols = ['constant'] + predictors\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "def pvalue(val, df = gwr.df_model):\n",
    "    return t.sf(abs(val), df)\n",
    "\n",
    "def sigstars(val):\n",
    "    stars = ''\n",
    "    if val < 0.1:\n",
    "        stars = stars + '*'\n",
    "    if val < 0.05:\n",
    "        stars = stars + '*'\n",
    "    if val < 0.001:\n",
    "        stars = stars + '*'\n",
    "    return stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate the coefficients - output is interpretable as the percent increase (or decrease) in the response for every one-unit increase in the independent variable.\n",
    "# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n",
    "ls = []\n",
    "for col,name in zip(gwr.params.T, cols):\n",
    "    min_,max_,med = (np.exp(col.min()) - 1) * 100, (np.exp(col.max()) - 1) * 100, (np.exp(np.median(col)) - 1) * 100\n",
    "    text = ''\n",
    "    text = text + '{:.3f} '.format(med)\n",
    "    text = text + '({:.3f}, '.format(min_)\n",
    "    text = text + '{:.3f})'.format(max_)\n",
    "    ls.append([min_,max_,med,text])\n",
    "gwr_coefficients = pd.DataFrame(ls, columns=['min','max','median','text'], index=cols)\n",
    "gwr_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate the coefficients - output is interpretable as the percent increase (or decrease) in the response for every one-unit increase in the independent variable.\n",
    "# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n",
    "ls = []\n",
    "for col,name in zip(gwr.params.T, cols):\n",
    "    min_,max_,med = (np.exp(col.min()) - 1) * 1, (np.exp(col.max()) - 1) * 1, (np.exp(np.median(col)) - 1) * 1\n",
    "    text = ''\n",
    "    text = text + '{:.3f} '.format(med)\n",
    "    text = text + '({:.3f}, '.format(min_)\n",
    "    text = text + '{:.3f})'.format(max_)\n",
    "    ls.append([min_,max_,med,text])\n",
    "gwr_coefficients = pd.DataFrame(ls, columns=['min','max','median','text'], index=cols)\n",
    "gwr_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I hate everything about this cell\n",
    "ls = []\n",
    "for params,tvals,index in zip(gwr.params,np.abs(gwr.filter_tvals(alpha=0.05)),X.index):\n",
    "    dict_ = {}\n",
    "    for param,tval,col in zip(params,tvals,cols):\n",
    "        dict_[col] = param if tval > 1.96 else np.nan\n",
    "    \n",
    "    ser = pd.Series(dict_,name=index)\n",
    "\n",
    "    ls.append(ser)\n",
    "\n",
    "params = pd.DataFrame(ls, columns=cols)\n",
    "params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform (exponentiate) for display\n",
    "\n",
    "cols_pct = ['renter_poverty', 'pct_foreignborn', 'pct_latino', 'rent_burden']\n",
    "cols_other = ['constant', 'gross_rent_paid_perpar_thousands', 'med_income_thousands']\n",
    "\n",
    "for col in cols_pct:\n",
    "    params[col] = params[col].apply(lambda x: (np.exp(x) - 1) * 1)\n",
    "\n",
    "for col in cols_other:\n",
    "    params[col] = params[col].apply(lambda x: (np.exp(x) - 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn GWR local parameter estimates into a GeoDataFrame with tract geometries\n",
    "# params = pd.DataFrame(gwr.params, columns=cols, index=X.index)\n",
    "params = gdf[['geometry']].merge(params, left_index=True, right_index=True, how='right')\n",
    "params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to generate colormaps for GWR plots\n",
    "def get_cmap(values, cmap_name='coolwarm', n=256):\n",
    "    import numpy as np\n",
    "    from matplotlib.colors import LinearSegmentedColormap as lsc\n",
    "    name = f'{cmap_name}_new'\n",
    "    cmap = plt.cm.get_cmap(cmap_name)\n",
    "    vmin = values.min()\n",
    "    vmax = values.max()\n",
    "\n",
    "    if vmax < 0:\n",
    "        # if all values are negative, use the negative half of the colormap\n",
    "        return lsc.from_list(name, cmap(np.linspace(0, 0.4, n))) #modified to avoid the middle of the colorspace\n",
    "    elif vmin > 0:\n",
    "        # if all values are positive use the positive half of the colormap\n",
    "        return lsc.from_list(name, cmap(np.linspace(0.6, 1, n))) #modified to avoid the middle of the colorspace\n",
    "    else:\n",
    "        # otherwise there are positive and negative values so use zero as midpoint\n",
    "        # and truncate the colormap such that if the original spans ± the greatest\n",
    "        # absolute value, we only use colors from it spanning vmin to vmax\n",
    "        abs_max = max(values.abs())\n",
    "        start = (vmin + abs_max) / (abs_max * 2)\n",
    "        stop = (vmax + abs_max) / (abs_max * 2)\n",
    "        return lsc.from_list(name, cmap(np.linspace(start, stop, n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the spatial distribution of local parameter estimates\n",
    "# set nrows, ncols to match your number of predictors!\n",
    "# Non-significant values mapped as gray (p<0.05)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(8, 9))\n",
    "fig=plt.figure(facecolor='white')\n",
    "\n",
    "\n",
    "for col, ax, name in zip(predictors, axes.flat, predictors_nicenames):\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{name}')\n",
    "    # gdf_param = params.dropna(subset=[col], axis='rows')\n",
    "    gdf_param = params\n",
    "    ax = gdf_param.plot(ax=ax,\n",
    "                  column=col,\n",
    "                  cmap=get_cmap(gdf_param[col].dropna(), cmap_name='bwr'),\n",
    "                  edgecolor='black',\n",
    "                  linewidth=0.1,\n",
    "                  legend=True,\n",
    "                  scheme='fisherjenks',\n",
    "                  legend_kwds={'prop':{'size':6}},\n",
    "                  missing_kwds={\"color\": \"lightgrey\", 'label':'p > 0.05'})\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('figures/local_coefficients.png', bbox_inches='tight', dpi=400, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn GWR local t-values into a GeoDataFrame with tract geometries\n",
    "# set t-values below significance threshold to zero then clip to ± 4\n",
    "# p<.05 corresponds to |t|>1.96, and |t|>4 corresponds to p<.0001\n",
    "tvals = pd.DataFrame(gwr.filter_tvals(alpha=0.05), columns=cols, index=X.index).clip(-4, 4)\n",
    "tvals = gdf[['geometry']].merge(np.abs(tvals), left_index=True, right_index=True, how='right')\n",
    "\n",
    "# plot the spatial distribution of local t-values\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(14, 6))\n",
    "for col, ax in zip(predictors, axes.flat):\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Local {col} $t$ values')\n",
    "    gdf_tval = tvals.dropna(subset=[col], axis='rows')\n",
    "    ax = gdf_tval.plot(ax=ax,\n",
    "                  column=col,\n",
    "                  cmap=get_cmap(gdf_tval[col]),\n",
    "                  legend=True,\n",
    "                  legend_kwds={'shrink': 0.6})\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('figures/local_tvalues.png', bbox_inches='tight', dpi=400, facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn GWR local R-squared values into a GeoDataFrame with tract geometries\n",
    "col = 'Local $R^2$ values'\n",
    "r_squared = pd.DataFrame(gwr.localR2, index=X.index, columns=[col])\n",
    "r_squared = gdf[['geometry']].merge(r_squared, left_index=True, right_index=True, how='right')\n",
    "\n",
    "# plot the spatial distribution of local R-squared values\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.set_aspect('equal')\n",
    "ax.axis('off')\n",
    "ax.set_title(col)\n",
    "gdf_local = r_squared.dropna(subset=[col], axis='rows')\n",
    "ax = gdf_local.plot(ax=ax,\n",
    "              column=col,\n",
    "              cmap='Reds',\n",
    "              legend=True,\n",
    "              legend_kwds={'shrink': 0.6})\n",
    "fig.tight_layout()\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('figures/local_r2values.png', bbox_inches='tight', dpi=400, facecolor='w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x, _y = gdf.loc[X.index].centroid.x, gdf.loc[X.index].centroid.y\n",
    "coords = np.array([_x, _y]).T\n",
    "threshold = ps.lib.weights.min_threshold_distance(coords)\n",
    "\n",
    "W = ps.lib.weights.distance.DistanceBand.from_dataframe(gdf.loc[X.index],\n",
    "                                                       threshold=threshold,\n",
    "                                                             binary=False,\n",
    "                                                             alpha=-1)\n",
    "W.transform = 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute OLS spatial diagnostics to check the nature of spatial dependence\n",
    "ols = ps.model.spreg.OLS(y=Y.values,\n",
    "                         x=X.values,\n",
    "                         w=W,\n",
    "                         name_x=X.columns.tolist(),\n",
    "                         name_y=response,\n",
    "                         spat_diag=True,\n",
    "                         moran=True,\n",
    "                         white_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate moran's I (for the response) and its significance\n",
    "mi = ps.explore.esda.Moran(y=Y, w=W, two_tailed=True)\n",
    "print(mi.I)\n",
    "print(mi.p_sim)\n",
    "print(mi.z_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White test (for homoskedasticity)\n",
    "print(ols.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate the coefficients - output is interpretable as the percent increase (or decrease) in the response for every one-unit increase in the independent variable.\n",
    "# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n",
    "for res,name in zip(((np.exp(ols.betas) - 1) * 100), ols.name_x):\n",
    "    print('{}: {}'.format(name,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate the coefficients - output is interpretable as the percent increase (or decrease) in the response for every one-unit increase in the independent variable.\n",
    "# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n",
    "for res,name in zip(((np.exp(ols.betas) - 1) * 1), ols.name_x):\n",
    "    print('{}: {}'.format(name,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moran's I (for the residuals): moran's i, standardized i, p-value\n",
    "ols.moran_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lagrange multiplier test for spatial lag model: stat, p\n",
    "ols.lm_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lagrange multiplier test for spatial error model: stat, p\n",
    "ols.lm_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust lagrange multiplier test for spatial lag model: stat, p\n",
    "ols.rlm_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust lagrange multiplier test for spatial error model: stat, p\n",
    "ols.rlm_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the robust error test is significant and the robust lag test is not, we will use a spatial error model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Error Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights matrix specification\n",
    "W_dist = ps.lib.weights.distance.DistanceBand.from_dataframe(gdf.loc[X.index],\n",
    "                                                       threshold=threshold,\n",
    "                                                             binary=False,\n",
    "                                                             alpha=-1)\n",
    "W_dist.transform = 'r'\n",
    "\n",
    "W_gravity = ps.lib.weights.distance.DistanceBand.from_dataframe(gdf.loc[X.index],\n",
    "                                                       threshold=threshold,\n",
    "                                                             binary=False,\n",
    "                                                             alpha=-2)\n",
    "W_gravity.transform = 'r'\n",
    "\n",
    "W_queen = ps.lib.weights.Queen.from_dataframe(gdf.loc[X.index])\n",
    "\n",
    "W_knn = ps.lib.weights.KNN.from_dataframe(gdf.loc[X.index], k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {'dist':W_dist, 'gravity':W_gravity, 'queen-contiguity':W_queen, 'k-nearest neighbors':W_knn}\n",
    "weights_output = {}\n",
    "for name, w in weights.items():\n",
    "    mle = ps.model.spreg.ML_Error(y=Y.values,\n",
    "                              x=X.values,\n",
    "                              w=w,\n",
    "                              method='full',\n",
    "                              name_w=name,\n",
    "                              name_x=X.columns.tolist(),\n",
    "                              name_y=response,\n",
    "                              name_ds='tracts')\n",
    "    weights_output[name] = mle.aic\n",
    "\n",
    "for name, aic in weights_output.items():\n",
    "    print('{}: {}'.format(name,aic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance-band (gravity model) weights matrix provides the best fit according to the Akaike information criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum-likelihood estimation with full matrix expression\n",
    "mle = ps.model.spreg.ML_Error(y=Y.values,\n",
    "                              x=X.values,\n",
    "                              w=W_gravity,\n",
    "                              method='full',\n",
    "                              name_w='gravity',\n",
    "                              name_x=X.columns.tolist(),\n",
    "                              name_y=response,\n",
    "                              name_ds='tracts')\n",
    "print(mle.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore Moran's I for the residuals\n",
    "mi_mle = ps.explore.esda.Moran(mle.e_filtered, W_gravity)\n",
    "print(mi_mle.I)\n",
    "print(mi_mle.p_sim)\n",
    "print(mi_mle.z_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the spatial autoregressive parameter estimate, lambda\n",
    "mle.lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate the coefficients - output is interpretable as the percent increase (or decrease) in the response for every one-unit increase in the independent variable.\n",
    "# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n",
    "for res,name in zip(((np.exp(mle.betas) - 1) * 100), mle.name_x):\n",
    "    print('{}: {}'.format(name,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponentiate the coefficients - output is interpretable as the percent increase (or decrease) in the response for every one-unit increase in the independent variable.\n",
    "# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n",
    "for res,name in zip(((np.exp(mle.betas) - 1) * 1), mle.name_x):\n",
    "    print('{}: {}'.format(name,res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (final)",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
